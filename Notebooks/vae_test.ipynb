{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import os \n",
    "import sys\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Adjust if needed\n",
    "\n",
    "# Add the project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from proteinshake.datasets import ProteinLigandInterfaceDataset, AlphaFoldDataset\n",
    "from src.utils import data_utils as dtu\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from src.models.basicVae import LitBasicVae\n",
    "import numpy as np\n",
    "from src.dataset_classes.sequenceDataset import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinLigandInterfaceDataset(root='../data').to_point().torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial testing to be done with proteins less than or equal to 150 residues in length\n",
    "max_seq_length = dtu.get_max_seq_len(dataset)\n",
    "seq_lengths = dtu.get_dataset_seq_lengths(dataset,leq = max_seq_length)\n",
    "total_num = sum(seq_lengths.values())\n",
    "total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(x, x_hat,x_mu, x_logvar):\n",
    "\n",
    "    rec_loss =  torch.nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    KL_loss = -0.5 * torch.sum(1 + x_logvar - x_mu.pow(2) - x_logvar.exp())\n",
    "\n",
    "    return (rec_loss + KL_loss) / x.size(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "seq_test_data = SequenceDataset(dataset)\n",
    "seq_dataloader = DataLoader(seq_test_data, batch_size=batch_size, shuffle=False)\n",
    "x_dim = seq_test_data[0].shape[0]\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.current_device()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicVae(latent_dim, x_dim, device).to(device)\n",
    "model_optim = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 8805.857168537297\n",
      "Epoch 1 Loss: 573.4133238073898\n",
      "Epoch 2 Loss: 486.7336163455493\n",
      "Epoch 3 Loss: 448.12906897557923\n",
      "Epoch 4 Loss: 427.8821528186537\n",
      "Epoch 5 Loss: 425.5512349899501\n",
      "Epoch 6 Loss: 1031.3734661781625\n",
      "Epoch 7 Loss: 448.97540769185105\n",
      "Epoch 8 Loss: 407.24881456976067\n",
      "Epoch 9 Loss: 514.6150695591757\n",
      "Epoch 10 Loss: 382.69239195732223\n",
      "Epoch 11 Loss: 367.11851961318763\n",
      "Epoch 12 Loss: 368.1743119644792\n",
      "Epoch 13 Loss: 353.2147185443199\n",
      "Epoch 14 Loss: 339.25786250911347\n",
      "Epoch 15 Loss: 376.5941721249933\n",
      "Epoch 16 Loss: 332.3824231918544\n",
      "Epoch 17 Loss: 336.3386949513056\n",
      "Epoch 18 Loss: 298.5822531817711\n",
      "Epoch 19 Loss: 282.57972617998513\n",
      "Epoch 20 Loss: 281.8378340838707\n",
      "Epoch 21 Loss: 360.15298825094146\n",
      "Epoch 22 Loss: 2382.794402396842\n",
      "Epoch 23 Loss: 542.9460882422043\n",
      "Epoch 24 Loss: 308.50129427975173\n",
      "Epoch 25 Loss: 277.3441021017832\n",
      "Epoch 26 Loss: 264.69404899910705\n",
      "Epoch 27 Loss: 258.6429685827804\n",
      "Epoch 28 Loss: 244.99498798422619\n",
      "Epoch 29 Loss: 245.98766264196945\n",
      "Epoch 30 Loss: 299.96424915365975\n",
      "Epoch 31 Loss: 3160.647018275849\n",
      "Epoch 32 Loss: 245.5950748234579\n",
      "Epoch 33 Loss: 246.16315569942944\n",
      "Epoch 34 Loss: 236.4380635823289\n",
      "Epoch 35 Loss: 240.06185416652733\n",
      "Epoch 36 Loss: 247.13829084945053\n",
      "Epoch 37 Loss: 226.75396381012382\n",
      "Epoch 38 Loss: 216.94485133967987\n",
      "Epoch 39 Loss: 214.7404137180276\n",
      "Epoch 40 Loss: 228.3484288045805\n",
      "Epoch 41 Loss: 207.1087346011645\n",
      "Epoch 42 Loss: 212.94231461825436\n",
      "Epoch 43 Loss: 323.84905676645775\n",
      "Epoch 44 Loss: 727699.9006998246\n",
      "Epoch 45 Loss: 280.23634100613526\n",
      "Epoch 46 Loss: 612.6864368752257\n",
      "Epoch 47 Loss: 350.0478078241218\n",
      "Epoch 48 Loss: 260.79058837890625\n",
      "Epoch 49 Loss: 269.37956582683404\n",
      "Epoch 50 Loss: 228.60433662101013\n",
      "Epoch 51 Loss: 229.67129218741638\n",
      "Epoch 52 Loss: 201.03581405012574\n",
      "Epoch 53 Loss: 195.2167573954961\n",
      "Epoch 54 Loss: 193.85770552125695\n",
      "Epoch 55 Loss: 188.39644055823757\n",
      "Epoch 56 Loss: 187.51669797505417\n",
      "Epoch 57 Loss: 198.37326073319946\n",
      "Epoch 58 Loss: 190.14627780653026\n",
      "Epoch 59 Loss: 189.31109250734931\n",
      "Epoch 60 Loss: 187.19180969342793\n",
      "Epoch 61 Loss: 180.31316689269184\n",
      "Epoch 62 Loss: 193.19250469991604\n",
      "Epoch 63 Loss: 215.26930200237118\n",
      "Epoch 64 Loss: 192.9730980494251\n",
      "Epoch 65 Loss: 189.37126807643943\n",
      "Epoch 66 Loss: 196.58073945241432\n",
      "Epoch 67 Loss: 187.88168457762836\n",
      "Epoch 68 Loss: 243.60630308438652\n",
      "Epoch 69 Loss: 250.27859609420986\n",
      "Epoch 70 Loss: 229.08623214617168\n",
      "Epoch 71 Loss: 213.09466267938484\n",
      "Epoch 72 Loss: 192.64484165139393\n",
      "Epoch 73 Loss: 185.68010992546604\n",
      "Epoch 74 Loss: 214.4627792149374\n",
      "Epoch 75 Loss: 190.44854158897923\n",
      "Epoch 76 Loss: 214.2748400544467\n",
      "Epoch 77 Loss: 213.35583535285846\n",
      "Epoch 78 Loss: 200.4384164940821\n",
      "Epoch 79 Loss: 204.5246693598081\n",
      "Epoch 80 Loss: 284.91953881146156\n",
      "Epoch 81 Loss: 742.387043600213\n",
      "Epoch 82 Loss: 249.3978664189169\n",
      "Epoch 83 Loss: 209.27260098392017\n",
      "Epoch 84 Loss: 215.21439202191078\n",
      "Epoch 85 Loss: 227.43050475969707\n",
      "Epoch 86 Loss: 234.5098680208807\n",
      "Epoch 87 Loss: 199.0960129254485\n",
      "Epoch 88 Loss: 180.6892523308323\n",
      "Epoch 89 Loss: 183.8174079738251\n",
      "Epoch 90 Loss: 233.5747091345591\n",
      "Epoch 91 Loss: 196.55259341409763\n",
      "Epoch 92 Loss: 256.5066707558828\n",
      "Epoch 93 Loss: 197.22059944884418\n",
      "Epoch 94 Loss: 214.22309922518795\n",
      "Epoch 95 Loss: 193.1387604752632\n",
      "Epoch 96 Loss: 201.22216762908516\n",
      "Epoch 97 Loss: 195.0305721335215\n",
      "Epoch 98 Loss: 180.25931891349896\n",
      "Epoch 99 Loss: 172.21866944718033\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        for batch_i, batch in enumerate(seq_dataloader):\n",
    "                # forward pass\n",
    "                x = batch[0].view(-1, x_dim).to(device)\n",
    "                rep_z, x_mu, x_logvar, x_rec = model(x)\n",
    "                loss = ELBO(x, x_rec,x_mu, x_logvar)\n",
    "                batch_losses.append(loss.data.cpu().item())\n",
    "                \n",
    "                model_optim.zero_grad()\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "        train_loss.append(sum(batch_losses)/len(batch_losses))\n",
    "        print(f\"Epoch {epoch} Loss: {train_loss[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=100,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    logger=TensorBoardLogger(save_dir=\"logs/\"))\n",
    "model = LitBasicVae(latent_dim, x_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name           | Type    | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | relu           | ReLU    | 0      | train\n",
      "1 | sig            | Sigmoid | 0      | train\n",
      "2 | fc1_enc        | Linear  | 47.5 M | train\n",
      "3 | fc3_enc_mean   | Linear  | 131 K  | train\n",
      "4 | fc3_enc_logvar | Linear  | 131 K  | train\n",
      "5 | fc1_dec        | Linear  | 131 K  | train\n",
      "6 | fc3_dec        | Linear  | 47.6 M | train\n",
      "---------------------------------------------------\n",
      "95.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "95.5 M    Total params\n",
      "381.895   Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96933066dd434ca59acbcf2a13426727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:339\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m--> 339\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:222\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 222\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py:279\u001b[0m, in \u001b[0;36mTQDMProgressBar.on_train_batch_end\u001b[0;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[0m\n\u001b[1;32m    278\u001b[0m _update_n(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar, n)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/callbacks/progress/progress_bar.py:198\u001b[0m, in \u001b[0;36mProgressBar.get_metrics\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    197\u001b[0m standard_metrics \u001b[38;5;241m=\u001b[39m get_standard_metrics(trainer)\n\u001b[0;32m--> 198\u001b[0m pbar_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n\u001b[1;32m    199\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(standard_metrics\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m&\u001b[39m pbar_metrics\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1637\u001b[0m, in \u001b[0;36mTrainer.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The metrics sent to the progress bar.\u001b[39;00m\n\u001b[1;32m   1632\u001b[0m \n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03mThis includes metrics logged via :meth:`~pytorch_lightning.core.LightningModule.log` with the\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m:paramref:`~pytorch_lightning.core.LightningModule.log.prog_bar` argument set.\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \n\u001b[1;32m   1636\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:254\u001b[0m, in \u001b[0;36m_LoggerConnector.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results:\n\u001b[0;32m--> 254\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_bar_metrics\u001b[38;5;241m.\u001b[39mupdate(metrics)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:235\u001b[0m, in \u001b[0;36m_LoggerConnector.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:493\u001b[0m, in \u001b[0;36m_ResultCollection.metrics\u001b[0;34m(self, on_step)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_metric\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprog_bar:\n\u001b[0;32m--> 493\u001b[0m         metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m][forked_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_tensors_to_scalars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:136\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_item\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:65\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:134\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ProteinManifoldLearning/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, seq_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "latent_coord = []\n",
    "model.eval()\n",
    "for batch_i, batch in enumerate(seq_dataloader):\n",
    "    # labels.append(batch[1].to('cpu').numpy())\n",
    "    # x = batch[0].view(-1, x_dim).to(device)\n",
    "    rep_z, x_mu, x_logvar, x_rec = model(batch)\n",
    "    latent_coord.append(x_mu.to('cpu').detach().numpy())\n",
    "# labels = np.concatenate(labels)``\n",
    "latent_coord = np.concatenate(latent_coord, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01262472, -0.09809753, -0.07252724, ...,  0.23386571,\n",
       "         0.12038825, -0.03749418],\n",
       "       [ 0.0594572 , -0.07933982,  0.10178749, ...,  0.09996183,\n",
       "         0.05545003,  0.08433231],\n",
       "       [ 0.05212124, -0.0873745 ,  0.11193117, ...,  0.08873858,\n",
       "         0.05037044,  0.08979265],\n",
       "       ...,\n",
       "       [ 0.06819684, -0.09151234,  0.09668663, ...,  0.07079172,\n",
       "         0.07146735,  0.10889755],\n",
       "       [ 0.06006777, -0.06574208,  0.09153965, ...,  0.09668906,\n",
       "         0.08513398,  0.07984908],\n",
       "       [ 0.06383976, -0.0957931 ,  0.10219815, ...,  0.0702812 ,\n",
       "         0.0666408 ,  0.10546778]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.pca_lowrank(torch.tensor(latent_coord), q=None, center=True, niter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_data = torch.matmul(torch.tensor(latent_coord), V[:, :2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x3c0242710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALlJJREFUeJzt3Qt0FOXdx/F/AiRBIAEESSIB5I7cDXcRpFACtQhILaItwVKsClaLWMEXRUGNl9bSCgfa+gr2CBZ5K3gtLaLCSwMiIEehgATBwAvhpkm4SMBk3/N/thuyyW6SDdndPLPfzzlzZmd2dneGIdlfnmuUy+VyCQAAgCWiw30CAAAAgSC8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACAACsUlscpqioSI4cOSINGjSQqKiocJ8OAACoBB0z9/Tp05KcnCzR0dGRFV40uKSkpIT7NAAAQBUcOnRImjdvHlnhRUtcPBcfHx8f7tMBAACVkJ+fbwofPN/jERVePFVFGlwILwAA2KUyTT5osAsAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAABApX33ncgXX7jX4UJ4AQAAlXL+vEjPniIdOoj07x++AEN4AQAAFdKg0ru3yM6d7u2tW0W+/FLCgvACAAAqpEHFE1xU164irVtLWBBeAABAhTSo9Op1Kbhs2SJSu7aERZg+FgAA2KR2bZFNm9wlMBpkwhVczLmE76MBAIBNatcWad8+3GdBtREAALAM4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAQGSElw0bNsioUaMkOTlZoqKiZPXq1V7PT5o0yewvuYwYMaLC9124cKG0atVK4uLipG/fvrJFR8EBAAC43PBy9uxZ6d69uwkb/mhYOXr0aPHy2muvlfueK1askOnTp8ucOXNk+/bt5v3T0tLk+PHjVT1NAADgMFUepG7kyJFmKU9sbKwkJiZW+j1feOEFmTJlitx5551me/HixfLuu+/Kyy+/LDNnzqzqqQIAAAcJapuXjz76SK666irp0KGD3HPPPXLq1Cm/x164cEG2bdsmw4YNu3Ry0dFme5OOR+xHQUGB5Ofney0AAMC5ghZetMroL3/5i6xbt06effZZWb9+vSmpKSws9Hn8yZMnzXPNmjXz2q/bOTk5fj8nIyNDEhISipeUlJRqvxYAAFBzBG1uo9tuu634cdeuXaVbt27Spk0bUxozdOjQavucWbNmmXYyHlryQoABAMC5QtZVunXr1tKkSRPJysry+bw+V6tWLTl27JjXft0ur92MtquJj4/3WgAAgHOFLLwcPnzYtHlJSkry+XxMTIykpqaaaiaPoqIis92/f/9QnSYAAHBqeDlz5ozs2LHDLOrAgQPmcXZ2tnnuoYceks2bN8vBgwdNABk9erS0bdvWdH320OqjBQsWFG9r9c+f//xneeWVV2T37t2mka92yfb0PgIAAKhym5etW7fKkCFDirc97U7S09Nl0aJF8tlnn5kQkpubawayGz58uMybN89U83js37/fNNT1GD9+vJw4cUIee+wx00i3R48esmbNmjKNeAEAQOSKcrlcLnEQbbCrvY7y8vJo/wIAgAO/v5nbCAAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACAACsQngBAABWIbwAAACrEF4AAIBVCC8AAMAqhBcAAGAVwgsAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAAAQGeFlw4YNMmrUKElOTpaoqChZvXp18XMXL16Uhx9+WLp27Sr16tUzx0ycOFGOHDlS7ns+/vjj5r1KLh07dqzqKQIAAAeqcng5e/asdO/eXRYuXFjmuXPnzsn27dvl0UcfNes33nhD9u7dKzfffHOF79u5c2c5evRo8bJx48aqniIAAHCg2lV94ciRI83iS0JCgqxdu9Zr34IFC6RPnz6SnZ0tLVq08H9CtWtLYmJiVU8LAAA4XMjavOTl5ZlqoIYNG5Z73L59+0w1U+vWreWOO+4wYac8BQUFkp+f77UAAADnCkl4OX/+vGkDM2HCBImPj/d7XN++fWXp0qWyZs0aWbRokRw4cEBuuOEGOX36tN/XZGRkmJIez5KSkhKkqwAAADVBlMvlcl32m0RFyapVq2TMmDFlntPGu+PGjZPDhw/LRx99VG54KS03N1datmwpL7zwgkyePNlvyYsuHlryogFGS3oC+SwAABA++v2thRCV+f6ucpuXytDg8uMf/1i++uor+eCDDwIOE1rF1L59e8nKyvJ7TGxsrFkAAEBkiA52cNE2LO+//75ceeWVAb/HmTNnZP/+/ZKUlBSUcwQAABEUXjRY7NixwyxK26foY21gq8HlRz/6kWzdulWWLVsmhYWFkpOTY5YLFy4Uv8fQoUNNLySPGTNmyPr16+XgwYOSmZkpY8eOlVq1apm2MgAAAJdVbaTBZMiQIcXb06dPN+v09HQz2Nxbb71ltnv06OH1ug8//FBuvPFG81hLVU6ePFn8nLaL0aBy6tQpadq0qQwcOFA2b95sHgMAAFRbg11bG/wAAAD7vr+Z2wgAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACAACsQngBAABWIbwAAACrEF4AAIBVCC8AAMAqhBcAAGAVwgsAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAEBnhZcOGDTJq1ChJTk6WqKgoWb16tdfzLpdLHnvsMUlKSpK6devKsGHDZN++fRW+78KFC6VVq1YSFxcnffv2lS1btlT1FAEAgANVObycPXtWunfvbsKGL88995z84Q9/kMWLF8vHH38s9erVk7S0NDl//rzf91yxYoVMnz5d5syZI9u3bzfvr685fvx4VU8TAAA4TJRLi0gu902iomTVqlUyZswYs61vqSUyDz74oMyYMcPsy8vLk2bNmsnSpUvltttu8/k+WtLSu3dvWbBggdkuKiqSlJQUue+++2TmzJmVOpf8/HxJSEgwnxcfH3+5lwYAAEIgkO/voLR5OXDggOTk5JiqIg89IQ0nmzZt8vmaCxcuyLZt27xeEx0dbbb9vQYAAESe2sF4Uw0uSktaStJtz3OlnTx5UgoLC32+Zs+ePX4/q6CgwCwlkxsAAHAu63sbZWRkmFIdz6LVTAAAwLmCEl4SExPN+tixY177ddvzXGlNmjSRWrVqBfQaNWvWLFM/5lkOHTpULdcAAAAiKLxcc801JnCsW7fOqzpHex3179/f52tiYmIkNTXV6zXaYFe3/b1GxcbGmoY9JRcAAOBcVW7zcubMGcnKyvJqpLtjxw5p3LixtGjRQh544AF58sknpV27dibMPProo6YHkqdHkho6dKiMHTtWpk2bZra1m3R6err06tVL+vTpI/Pnzzddsu+8887LvU4AABDp4WXr1q0yZMiQ4m0NHkrDh3aH/vWvf22Cx1133SW5ubkycOBAWbNmjRl8zmP//v2moa7H+PHj5cSJE2ZwO23Y26NHD/Oa0o14AQBA5KqWcV5qEsZ5AQDAPmEf5wUAACBYCC8AAMAqhBcAAGAVwgsAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACAACsQngBAABWIbwAAACrEF4AAIBVCC8AAMAqhBcAAGAVwgsAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsENby0atVKoqKiyixTp071efzSpUvLHBsXFxfMUwQAAJapHcw3/+STT6SwsLB4e+fOnfL9739fbr31Vr+viY+Pl7179xZva4ABAAAISXhp2rSp1/Yzzzwjbdq0kcGDB/t9jYaVxMTEYJ4WAACwWMjavFy4cEFeffVV+dnPflZuacqZM2ekZcuWkpKSIqNHj5Zdu3aV+74FBQWSn5/vtQAAAOcKWXhZvXq15ObmyqRJk/we06FDB3n55ZflzTffNEGnqKhIBgwYIIcPH/b7moyMDElISCheNPQAAADninK5XK5QfFBaWprExMTI22+/XenXXLx4UTp16iQTJkyQefPm+S150cVDS140wOTl5Zn2MwAAoObT728thKjM93dQ27x4fPXVV/L+++/LG2+8EdDr6tSpIz179pSsrCy/x8TGxpoFAABEhpBUGy1ZskSuuuoquemmmwJ6nfZU+vzzzyUpKSlo5wYAAOwS9PCi7VY0vKSnp0vt2t4FPRMnTpRZs2YVb8+dO1f++c9/ypdffinbt2+Xn/zkJ6bU5uc//3mwTxMAAFgi6NVGWl2UnZ1tehmVpvujoy/lp2+++UamTJkiOTk50qhRI0lNTZXMzEy59tprg32aAADAEiFrsFsTG/wAAAD7vr+Z2wgAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACAACsQngBAABWIbwAAACrEF4AAIBVCC8AAMAqhBcAAGAVwgsAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYJWghpfHH39coqKivJaOHTuW+5qVK1eaY+Li4qRr167y3nvvBfMUAQCAZYJe8tK5c2c5evRo8bJx40a/x2ZmZsqECRNk8uTJ8umnn8qYMWPMsnPnzmCfJgAAsETQw0vt2rUlMTGxeGnSpInfY3//+9/LiBEj5KGHHpJOnTrJvHnz5LrrrpMFCxYE+zQBAIAlgh5e9u3bJ8nJydK6dWu54447JDs72++xmzZtkmHDhnntS0tLM/v9KSgokPz8fK8FAAA4V1DDS9++fWXp0qWyZs0aWbRokRw4cEBuuOEGOX36tM/jc3JypFmzZl77dFv3+5ORkSEJCQnFS0pKSrVfBwAAiJDwMnLkSLn11lulW7dupgRFG9/m5ubK66+/Xm2fMWvWLMnLyyteDh06VG3vDQAAap7aofywhg0bSvv27SUrK8vn89om5tixY177dFv3+xMbG2sWAAAQGUI6zsuZM2dk//79kpSU5PP5/v37y7p167z2rV271uwHAAAIeniZMWOGrF+/Xg4ePGi6QY8dO1Zq1aplukOriRMnmmofj/vvv9+0j/ntb38re/bsMePEbN26VaZNm8bdAgAAwa82Onz4sAkqp06dkqZNm8rAgQNl8+bN5rHSnkfR0Zfy04ABA2T58uUye/ZseeSRR6Rdu3ayevVq6dKlSzBPEwAAWCTK5XK5xEG0q7T2OtLGu/Hx8eE+HQAAUM3f38xtBAAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwCuEFAABYhfACq3z3ncgXX7jXAIDIRHiBNTSw6BydHTq41wQYAIhMhBdY48svRbZudT/WtW4DACIP4QXWaN1apFcv9+Pevd3bAIDIE9RZpYHqVLu2yKZN7hIXDS66DQCIPPz6h1U0sLRvH+6zAACEE9VGAbjlFpGoKPcaAACEB+GlkjSwrFrlfqzrESPCfUYAAEQmwksleYKLxz/+IXLyZLjOBgCAyEV4qaSbbiq774knwnEmAABENsJLJY0dW3bfwIHhOBMAACIb4aWSxo93N9b1iI0VGT06nGcEAEBkoqt0JdWvL5KfL/LqqyLNmomMHCkSFxfuswIAIPIQXgIMMHffHe6zAAAgslFtBAAArEJ4gfV0dukvvmCWaQCIFIQXWE0DS//+Ih06uNcVBRiCDgDYj/ACq+kkjVu3uh/rWrerK+gAAGomwgusprNL9+rlfty7t3u7OoIOAKDmIrzA+lmmN20S2btXJDPTvV0dQQcAUHMRXsKMNhiX/++lgaV9+/KDS6BBBwBQcxFeqiA3V+Spp9zry0EbjND/e1U26AAAai7CS4A0sDRqJDJ7tnt9OQGGNhiB4d8LAKAILwFauLD87UDQBuPy/r1atAi8yu1yqumo4gOACAgvGRkZ0rt3b2nQoIFcddVVMmbMGNmrDQ7KsXTpUomKivJa4mrQJEJTp5a/HYjy2mDoF+S//+1e+LIs+++1YYPIDTeUX4VUOmzouk8f92vq1BF56aXKfzZVfAAQIeFl/fr1MnXqVNm8ebOsXbtWLl68KMOHD5ezZ8+W+7r4+Hg5evRo8fLVV19JTdGwocg334g8+aR7rduXw1cbDP1i7NdPpHNn96KP+bL0/vfKzi6/CslX2PjsM5FPP710zJQplQ8wVFkBQM0R5XK5XKH6sBMnTpgSGA01gwYN8lvy8sADD0huFRuT5OfnS0JCguTl5ZkQZCMtLdAv3ZK0tEG/tCPd+fMaikWuv15kyBB3kNAqpNIlV6X/DfXfT193111l3/PixYob8HrCkL/PAwBcnkC+v0Pa5kVPSDVu3Ljc486cOSMtW7aUlJQUGT16tOzatcvvsQUFBeaCSy5OaNuRmnppW9t50B7GHVyuvFJkxAiRZs1EPvzQf7dnX+2JJkzw/b6VKUWhmzUA1BwhCy9FRUWmROX666+XLl26+D2uQ4cO8vLLL8ubb74pr776qnndgAED5PDhw37b1WhS8ywaeGynX4ybN4toZtNFvzT5snSXnJw7536s63/9y3+3Z19ho359d1XfFVdULRjSzRoAIqza6J577pG///3vsnHjRmnevHmlX6ftZDp16iQTJkyQefPm+Sx50cVDS140wNhcbYTyS140uGgAOXVKpCptuT0NeRVhBADsqzYKya/tadOmyTvvvCMbNmwIKLioOnXqSM+ePSUrK8vn87GxsWaB82lQ0cCiJTCDB1ctuCgNK9deW91nBwBwRLWRFupocFm1apV88MEHcs011wT8HoWFhfL5559LUlJSUM4RdtHAkpZW9eACALBfUEtetJv08uXLTfsVHeslJyfH7Ndiobp165rHEydOlKuvvtq0XVFz586Vfv36Sdu2bU2Po+eff950lf75z38ezFMFAACWCGp4WbRokVnfeOONXvuXLFkikyZNMo+zs7MlOvpSAdA333wjU6ZMMUGnUaNGkpqaKpmZmXIt5fwAACDU47yEghPGeQEAINLk19RxXoBgOnhQ5Pvfd68BAM5FeIEjaGDR9uDvv+9eewLMmTMif/6ze1oAplgAAGdghAs4wi23lN3WyRu15NFTMdqzp8iWLYzrAgC2o+QFNXZAun/8w72ujNKTlev2ihWXgovS0hcdnE5HL05MdK8BAPYhvKDG0VChPel1DiOdBkurfkrTff/935eee+st7+d1e9y4sq/TmaV1gsVjx9xrAgwA2Ifwghplxw53qPD49luR667zbq+igUWrg3ToH13r9tCh7vYuDRq417p9/Lj3e3furKM9e+8bM6bicyodlCoz9QDtawAgeAgvqFF8lZbs2+c983PJ6iBd67bSwKKTiuu69MzSOheoziKh0wuUVK9e+UHDV1DyR99Hg1eHDu41AQYAgoPwghrlb38ru693b++Zn8ePF4mKcj/WtW77UnJmaQ0427eXPUZDkTbi9cdfUPJF32vrVvdjXZcMXACA6kN4QY3So4e7Ya2GlU8+cQePzEzvHkL167tLWF56yb3WbV927hTp2lXkwgX3++lM1L68/rr/86lsUCpd0lM6cAEAqg8j7MIKWl2jpR4aHnyFFa2i0ZIODQwadDzBxeOdd0R++EPf733ihEiTJhV/9ujR7pIcpYPh+ZocsvR5AAAqhxF24SgVtTvx1dbk1lu9j5kx41KpiK51DBhtvKulOg0blm1oW7KRroYlDS46sfnNN7uXRo18d+PWwNK+PcEFAIKJ8IIar6J2J77amqxc6X2Mbnvav+ja0016wACRfv3ciyf85OZ6hyWdDL1pU+8GuBpc1q8P9pUDAHwhvKDGq6jdia+2Jtq76PPPRTp2dK91u2SpSMnAs22be1G6b+FC77CkpTalxcSIDB4cvGsGAPhHeEGNV1ED3ZK9iko27tXAsnu3u+2Lhh5dPFVOJQOPrlNT3Y913bat9/v/z/94b199tXuQO19tXgAAwUeDXVitvAay+lydOmVfc/q0OwCVfK3SoNO3r3tgvNKWLRO5445L2zpw3scf07YFAKoLDXYREcobFE4f64i6vmibmTffdHed1sCiAUSXI0d8Bxc97uRJ7306Zow28GU0XQAIPcILrJ2wsbxB4fSxBgtfdFRdnRbg4kX3WoOM0jYsJceC0Vmo333XPSpvcrL3e2hpzcSJjKYLAOFAoTesoYHlyitFzp1zhwxtd6LtVTS4lB4UTh9r49zSAebQobKDx2m3ah3ITtuwaFD54AOR5s1Frr3WXSKjwSQj49Lxepz2XvK0k/EEJ/08AEDwUfKCsNBB5Dp1cq8rS7sma3BRuv7Xv3w31FX6eNcukVdfdXd3njRJ5Jtv3OO1aIlLSZ5u1RpSsrNFhg8X6dbt0vtpMCk5tYCW/Giw0QbBitF0ASC0aLCLkCs9+q2nK3OgJS9aShJIjx8tKSk9v9Hq1e5Ao++tIUTPTUtzNBR5wouGGn1OZ7wuOY2Bbut56zQG9DwCgMtDg13UaKVHvy297Y+nWmfNmsCDi/I1MWNamkhWlnt6AE8pkKcayDPqrho40Pt1niCjr9m4sXKfr5+jg+LpGgBQdYQXhJyv0W8rSwOLBo6qlHRo9+bSnnlGpF07kbNnL+1r0EDk66/d47log1ztPq2ByR+d5+jgwfI/WwOLfo6W6OiaAAMAVUd4Qcj5Gv02FDyj6Jb03HO+x4HRHkTHj18qsakobEyZUnafDqqnA+PNnSvy0596P6c9lQAAVUN4QVh4Rr8NRXApOcmihqWS/va36vmM22/3nqhRg4sn0MyZ425UXNJf/lI9nwsAkYjwgoiakVq7QL/11qVSn5EjRQ4cEBk2TOR//9f3e9Sq5V5rI2Gt8vHlZz8TadxYZNEi92eWLonRnk7aS0lLdPbtKzsFAQCg8ggviKgZqbWX0M03u6cH0ACjWrUSWbvW3ShXx4H54Q+930NnldY2L1p6ou1bPGGmNB2d99573W1mfvzjss/rODDapZvgAgCXh67ScPQ8R56SF/1fru1PSv5v1zDib2A5fZ0GH53BWoOOTg/QtOnln6OW8uiAeL7mYgKASJZPV2lEGn/zHJWckVp7EHlmkq5oYDl93eTJl2aw1nYr1UGnHGBKAQC4PIQXOEJ58xx5gkjDhv5H5K1IdVX15OZeOsd33iHAAEBVEF7gCFqKUplSFQ0sWlUUaJWNr67Ql2vsWPe5EmAAIDCEFziChpGqlqpUhpbe6Pgvv/mN936druBy6Ei9WiJUcuoBAEANCC8LFy6UVq1aSVxcnPTt21e2bNlS7vErV66Ujh07muO7du0q7733XihOE5araqlKIAHmwQfdvYq095F2fy45Mm9V6XtoWxgCDADUkPCyYsUKmT59usyZM0e2b98u3bt3l7S0NDnuGb60lMzMTJkwYYJMnjxZPv30UxkzZoxZdgYy/TAQRJ4pCj7+2HtguuRkkf/6r6q/77hx1XJ6AOB4Qe8qrSUtvXv3lgULFpjtoqIiSUlJkfvuu09mzpxZ5vjx48fL2bNn5R1tzfgf/fr1kx49esjixYsr/Dy6SiNUNLjowHRaEuOh1VYFBSLdugX+fp9+6h6HBgAiUX5N6Sp94cIF2bZtmwzT4Us9HxgdbbY3aQMFH3R/yeOVltT4O76goMBccMkFCFUJzJEjIrGxl0bgbdFCpFOnS42HNYxMmFC59yO4AEDlBDW8nDx5UgoLC6VZs2Ze+3U7R4ct9UH3B3J8RkaGSWqeRUt1gFDR2k8taVHnzomsX+9+7Gk8/MknIsuXi1y8KDJvnv/30QH0AAAR0tto1qxZpojJsxzS8d2BMHTR1pKXESPcA9Cpko2HdT17tsjRo1qVWvZ9/v3vEJ40AFguqOGlSZMmUqtWLTl27JjXft1OTEz0+RrdH8jxsbGxpm6s5AKEuou29j7SkhfPAHTr1vkev0X/G2/e7J4mQEOMVjHp7NqeeZYAAGEOLzExMZKamirr9Df5f2iDXd3u7/nztBTdX/J4tXbtWr/HAzWBZuaYmEtVQJ4SGH8D0OlkkBpitMSF4AIAgQn61HDaTTo9PV169eolffr0kfnz55veRHfeead5fuLEiXL11Vebtivq/vvvl8GDB8tvf/tbuemmm+Svf/2rbN26Vf70pz8F+1SBgB0+7O5ZpGO+eHj673mmKfA3+SMAoIaGF+36fOLECXnsscdMo1vt8rxmzZriRrnZ2dmmB5LHgAEDZPny5TJ79mx55JFHpF27drJ69Wrp0qVLsE8VCIi2IffVPlxLYHTm6IomfwQA1NBxXkKNcV4QKpMmibzyStn92gZGx3/R4BKs0X4BwGlqzDgvgFNo25UvvvBuw/LMM2WPu+46d++jYE5TAACRjvACVEADiza+7dDBuxGu9hzSrs/p6SLaQ1/HddEpAwgtABBcVBsBFdASFw0uHhpSaIQLANWLaiMgSAPR0QgXAMKP8AJUciA6LXHJzBTJzRX51a90+otwnxkARCbCC1DJAKNVRRpcmjYVmT/fvSbAAEDoEV6AADz1lPf2k0+G60wAIHIRXoAAuko//LD3fp1F2t8UAACA4CC8AAF0lR41SmTDhkvP7djhngIAABA6hBegAhpOdJ4ipesrr6T3EQCEE+EFCLCrtDbcLdn7iEHpACC0+LULVLKrtJbAlJyviIHqACA8CC9AAF2lAQDhR7URAACwCuEFAABYhfACAACsQngBAABWIbwAAACrEF6ASk4NwDQAAFAzEF6ASk4NoGsCDACEH+EFCGBqAOYxAoDwI7wAAUwNwDxGABB+jLALVGFqAABA+PCrGKgAUwMAQM1CtREAALAK4QUAAFiF8AIAAKxCeAEAAFYhvAAAAKsQXgAAgFUIL4gozFMEAPYLSng5ePCgTJ48Wa655hqpW7eutGnTRubMmSMXLlwo93U33nijREVFeS133313ME4RET5PUc+eIufPh/uMAAA1ZpC6PXv2SFFRkfzxj3+Utm3bys6dO2XKlCly9uxZ+c1vflPua/W4uXPnFm9fccUVwThFRPg8RTt3uof7//RTRs0FANsE5df2iBEjzOLRunVr2bt3ryxatKjC8KJhJTExMRinhQinw/t36eIOLkrXGmgYPRcA7BKyNi95eXnSuHHjCo9btmyZNGnSRLp06SKzZs2Sc+fOheT8EDnzFNWt697WQr0WLcJ9VgCAQIWkwDwrK0tefPHFCktdbr/9dmnZsqUkJyfLZ599Jg8//LApsXnjjTf8vqagoMAsHvn5+dV67nBOexctZdH1t9+692kuzs6m5AUAbBPlcrlclT145syZ8uyzz5Z7zO7du6Vjx47F2//3f/8ngwcPNo1xX3rppYBO7oMPPpChQ4ea8KONfn15/PHH5YknnvBZ0hMfHx/Q58HZDXW1vUtqqnvftm3uNi+ZmbR5AYCaQAsfEhISKvX9HVB4OXHihJw6darcY7R9S0xMjHl85MgRE1r69esnS5culejowGqptIFv/fr1Zc2aNZKWllbpkpeUlBTCC4pp12jtYeSxa5c7sGgbGIILANgXXgL61d20aVOzVIaWuAwZMkRSU1NlyZIlAQcXtWPHDrNOSkrye0xsbKxZAH80pPTq5S550dIWrSYitACAvYLSYFeDi5a4tGjRwrRz0RKbnJwcs5Q8RquXtmzZYrb3798v8+bNk23btplxYt566y2ZOHGiDBo0SLp16xaM04TD6Tgu//iHu9pIG+ru3Us1EQA4QVB+ja9du9a0U9GlefPmXs95aqkuXrxoGuN6ehNpVdP7778v8+fPN9VFWvUzbtw4mT17djBOEREQXLRzmzbO1YK5kydpmAsAThFQmxen1ZnBud5+W+Tmmy9ta3vvPXsodQEAJ3x/M7cRHKl0JN+/391VGgBgP8ILHGnQIO9tnctIG+4CAOxHeIEjffyx9/aTT1JlBABOQXiB42jvouRk72kAvve9cJ8VAKC6EF7gKLm5Im3bimjv+k6dRN59V0THVYyLC/eZAQCqCwXpcAztDl1yDMXt20VatSK4AIDTUPICR9DxDys5+DMAwHKEFziiqsjXDBLaw4iB6QDAeQgvsN4DD5Tdd911IjrzBD2MAMB5CC+wWlaWyCuvlN3/y18SXADAqQgvsLqBbrt2vp8bPz7UZwMACBXCC6w1erTv/cuW0cMIAJyM8AJrZWaW3RcVJXLLLeE4GwBAqBBeYCWdIdqXF1+k1AUAnI7wAit16eJ7f3p6qM8EABBqhBdYOa5LYWHZ/UePitSvH44zAgCEEuEF1mnTpuy+7t1FEhPDcTYAgFAjvMAqjzwi8vXXZfdv3BiOswEAhAPhBVbJyPC9n+oiAIgchBdYZdassvs2bQrHmQAAwoXwAqs8/fSlAKPD/2tw6dcv3GcFAAilKJfL5RIHyc/Pl4SEBMnLy5P4+Phwnw4AAKjm729KXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACAVQgvAADAKoQXAABgFcILAACwSm1xGM88kzrBEwAAsIPne7sy80U7LrycPn3arFNSUsJ9KgAAoArf4zq7dHmiXJWJOBYpKiqSI0eOSIMGDSQqKqrClKch59ChQxVOv22rSLjGSLlOrtEZuEbniITrzA/hNWoc0eCSnJws0dHRkVXyohfcvHnzgF6jN8Sp//Ei6Roj5Tq5RmfgGp0jEq4zPkTXWFGJiwcNdgEAgFUILwAAwCoRHV5iY2Nlzpw5Zu1UkXCNkXKdXKMzcI3OEQnXGVtDr9FxDXYBAICzRXTJCwAAsA/hBQAAWIXwAgAArEJ4AQAAVonY8PLUU0/JgAED5IorrpCGDRv6PEZH6C29/PWvfxUnXWN2drbcdNNN5pirrrpKHnroIfnuu+/EZq1atSpz35555hmx2cKFC811xcXFSd++fWXLli3iJI8//niZe9axY0ex2YYNG2TUqFFmtFC9ntWrV3s9r30lHnvsMUlKSpK6devKsGHDZN++feKka5w0aVKZ+zpixAixSUZGhvTu3duM2q6/I8eMGSN79+71Oub8+fMydepUufLKK6V+/foybtw4OXbsmDjpGm+88cYy9/Luu+8O2zlHbHi5cOGC3HrrrXLPPfeUe9ySJUvk6NGjxYveVKdcY2FhoQkuelxmZqa88sorsnTpUvML1XZz5871um/33Xef2GrFihUyffp0011x+/bt0r17d0lLS5Pjx4+Lk3Tu3Nnrnm3cuFFsdvbsWXOvNHj68txzz8kf/vAHWbx4sXz88cdSr149c1/1i9Ap16g0rJS8r6+99prYZP369SaYbN68WdauXSsXL16U4cOHm2v3+NWvfiVvv/22rFy50hyvU9Tccsst4qRrVFOmTPG6l/p/OGxcEW7JkiWuhIQEn8/pP8+qVatcTr3G9957zxUdHe3Kyckp3rdo0SJXfHy8q6CgwGWrli1bun73u9+5nKJPnz6uqVOnFm8XFha6kpOTXRkZGS6nmDNnjqt79+4upyr9u6SoqMiVmJjoev7554v35ebmumJjY12vvfaay0a+fl+mp6e7Ro8e7XKS48ePm2tdv3598X2rU6eOa+XKlcXH7N692xyzadMmlxOuUQ0ePNh1//33u2qKiC15qSxNo02aNJE+ffrIyy+/XKmpum2xadMm6dq1qzRr1qx4n/7lpxNx7dq1S2ym1URahNuzZ095/vnnra0K01Kxbdu2mSqFkvN36bbePyfRKhOtfmjdurXccccdpkrTqQ4cOCA5OTle91XndNEqQafd148++shURXTo0MGUAp86dUpslpeXZ9aNGzc2a/351JKKkvdSqzxbtGhh7b3MK3WNHsuWLTPfh126dJFZs2bJuXPnwnSGDpyYsbqrHr73ve+Z9iD//Oc/5d5775UzZ87IL3/5S3EC/eVZMrgoz7Y+Zyu9P9ddd535wdPqMP0h0yLOF154QWxz8uRJU73n6z7t2bNHnEK/tLXKUr/g9F498cQTcsMNN8jOnTtNPbzTeH6+fN1Xm3/2fFUZafXJNddcI/v375dHHnlERo4cab7Ua9WqJbYpKiqSBx54QK6//nrzBa70fsXExJRpV2jrvSzycY3q9ttvl5YtW5o/MD777DN5+OGHTbuYN954Iyzn6ajwMnPmTHn22WfLPWb37t2Vbgj46KOPFj/Wv+C1/k//ig9neKnua7RFINet7UM8unXrZn6x/OIXvzCN0mraENdw0y+0kvdMw4z+onz99ddl8uTJYT03VN1tt91W/FhLefXetmnTxpTGDB06VGwsiddAbXt7rKpc41133eV1L7Whud5DDaV6T0PNUeHlwQcfNK3by6NF0lWlv1DnzZsnBQUFYfsSrM5rTExMLNNrxdNCXp+rSS7nuvW+abXRwYMHzV/2NtEiWv0LtXTPBd2uafeoOulfse3bt5esrCxxIs+90/uoXwIeut2jRw9xKv0Z1f/Tel9tCy/Tpk2Td955x/Swat68ude91Ord3Nxcr9IXG39Gp/m5Rn+/V5XeS8LLZWratKlZgmXHjh3SqFGjsP71Xp3X2L9/f9OdWnutaJ200pbm8fHxcu2110pNcjnXrfdN24l4rtEmWmqUmpoq69atK+7ppsW6uq2/aJxKq2f1L7qf/vSn4kRajaJfbHofPWFF25ppr6OKekDa7PDhw6bNS8nAVtNpO0ftrbhq1SpTYqT3riT9+axTp465l9pFWml1irbZ0t+xTrhGf79XVbjupaPCSyD0P9bXX39t1tqmwHMj2rZta/rpa7c3Tc79+vUzY2vol/rTTz8tM2bMEKdco3aF05CiXxDa5U3rZ2fPnm2KDW2tXtG6dP0CGDJkiGkrodvajfEnP/mJCZ420mqw9PR06dWrl2k4Pn/+fFOFeeedd4pT6M+VjheiVUXazVS7hWuJ04QJE8TmAFay5Egb6erPoLbF0sac2q7gySeflHbt2pkvC62m1vYENg3HUN416qJtl/QLXYOahtFf//rX5vePdgywhf4+XL58ubz55pvmd4qnHYs2sNbxeXStVZv6c6rXrH/8aRDQ4KLfH064xv3795vnf/CDH5iOENrmRX+vDho0yFQFhoUrQmkXPr380suHH35onv/73//u6tGjh6t+/fquevXqmW6cixcvNt1UnXKN6uDBg66RI0e66tat62rSpInrwQcfdF28eNFlq23btrn69u1ruobHxcW5OnXq5Hr66add58+fd9nsxRdfdLVo0cIVExNjuk5v3rzZ5STjx493JSUlmeu7+uqrzXZWVpbLZvpz5uvnT38uPd2lH330UVezZs1MF+mhQ4e69u7d63LKNZ47d841fPhwV9OmTU1XYh3CYMqUKV5DM9jA1/XpokNQeHz77beue++919WoUSPXFVdc4Ro7dqzr6NGjLqdcY3Z2tmvQoEGuxo0bm/+rbdu2dT300EOuvLy8sJ1z1H9OHAAAwAqM8wIAAKxCeAEAAFYhvAAAAKsQXgAAgFUILwAAwCqEFwAAYBXCCwAAsArhBQAAWIXwAgAArEJ4AQAAViG8AAAAqxBeAACA2OT/ARB2WHKGeDwFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(projected_data.numpy()[:, 0], projected_data.numpy()[:, 1], s = 2, color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProteinManifoldLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
