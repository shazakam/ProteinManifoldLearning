{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gpytorch\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Adjust if needed\n",
    "\n",
    "# Add the project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from proteinshake.datasets import ProteinLigandInterfaceDataset\n",
    "from src.utils import data_utils as dtu\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProteinLigandInterfaceDataset(root='../data').to_point().torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial testing to be done with proteins less than or equal to 150 residues in length\n",
    "max_seq_length = 150\n",
    "seq_lengths = dtu.get_dataset_seq_lengths(dataset,leq = max_seq_length)\n",
    "total_num = sum(seq_lengths.values())\n",
    "total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_tensors(tensor_list):\n",
    "    max_length = max([x.shape[0] for x in tensor_list])\n",
    "    padded_tensors = []\n",
    "    for tensor in tensor_list:\n",
    "        cur_size = tensor.shape[0]\n",
    "        pad_size = max_length - cur_size\n",
    "        padding = torch.zeros(pad_size, tensor.shape[1])\n",
    "        padd_tensors = torch.cat((tensor, padding), 0)\n",
    "        padded_tensors.append(padd_tensors)\n",
    "    return torch.stack(padded_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = dtu.get_subset_leq_len(dataset,leq = max_seq_length)\n",
    "tensor_list = [sample[0][:,:] for sample in data_subset]\n",
    "padded_tensors = padd_tensors(tensor_list)\n",
    "Y = padded_tensors\n",
    "\n",
    "min_val = Y.min()\n",
    "max_val = Y.max()\n",
    "Y = (Y - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2614, 0.3603, 0.2078, 0.2674, 0.2544, 0.3639, 0.1993, 0.2585, 0.2520,\n",
       "        0.3526, 0.1978, 0.2405, 0.2480, 0.3521, 0.2086, 0.2376, 0.2422, 0.3620,\n",
       "        0.2074, 0.2376, 0.2375, 0.3576, 0.1977, 0.2316, 0.2344, 0.3481, 0.2033,\n",
       "        0.2704, 0.2290, 0.3542, 0.2115, 0.2614, 0.2241, 0.3606, 0.2034, 0.2256,\n",
       "        0.2201, 0.3510, 0.1983, 0.2376, 0.2162, 0.3474, 0.2084, 0.2525, 0.2106,\n",
       "        0.3574, 0.2100, 0.2256, 0.2062, 0.3570, 0.1994, 0.2495, 0.2029, 0.3462,\n",
       "        0.2017, 0.2614, 0.1983, 0.3489, 0.2118, 0.2525, 0.1929, 0.3581, 0.2078,\n",
       "        0.2256, 0.1884, 0.3514, 0.1996, 0.2286, 0.1847, 0.3435, 0.2070, 0.2794,\n",
       "        0.1808, 0.3517, 0.2139, 0.2704, 0.1752, 0.3571, 0.2055, 0.2465, 0.1702,\n",
       "        0.3473, 0.2022, 0.2256, 0.1666, 0.3459, 0.2128, 0.2525, 0.1633, 0.3568,\n",
       "        0.2140, 0.2226, 0.1568, 0.3567, 0.2044, 0.2495, 0.1512, 0.3471, 0.2075,\n",
       "        0.2316, 0.1407, 0.3503, 0.2113, 0.2555, 0.1413, 0.3423, 0.2195, 0.2256,\n",
       "        0.1504, 0.3478, 0.2244, 0.2614, 0.1466, 0.3588, 0.2241, 0.2256, 0.1456,\n",
       "        0.3591, 0.2356, 0.2794, 0.1569, 0.3567, 0.2365, 0.2614, 0.1601, 0.3651,\n",
       "        0.2293, 0.2704, 0.1592, 0.3736, 0.2371, 0.2555, 0.1622, 0.3752, 0.2479,\n",
       "        0.2644, 0.1535, 0.3739, 0.2555, 0.2794, 0.1502, 0.3850, 0.2568, 0.2316,\n",
       "        0.1530, 0.3873, 0.2677, 0.2644, 0.1429, 0.3927, 0.2701, 0.2316, 0.1357,\n",
       "        0.3854, 0.2649, 0.2376, 0.1413, 0.3777, 0.2715, 0.2794, 0.1469, 0.3814,\n",
       "        0.2808, 0.2644, 0.1482, 0.3709, 0.2855, 0.2316, 0.1539, 0.3670, 0.2762,\n",
       "        0.2764, 0.1635, 0.3722, 0.2796, 0.2794, 0.1647, 0.3665, 0.2897, 0.2704,\n",
       "        0.1596, 0.3566, 0.2869, 0.2794, 0.1669, 0.3559, 0.2779, 0.2495, 0.1778,\n",
       "        0.3577, 0.2813, 0.2555, 0.1821, 0.3583, 0.2706, 0.2405, 0.1742, 0.3623,\n",
       "        0.2634, 0.2644, 0.1763, 0.3599, 0.2524, 0.2585, 0.1711, 0.3612, 0.2422,\n",
       "        0.2316, 0.1736, 0.3607, 0.2310, 0.2525, 0.1754, 0.3721, 0.2306, 0.2674,\n",
       "        0.1832, 0.3710, 0.2389, 0.2674, 0.1876, 0.3621, 0.2332, 0.2794, 0.1887,\n",
       "        0.3687, 0.2238, 0.2495, 0.1936, 0.3772, 0.2299, 0.2674, 0.2008, 0.3696,\n",
       "        0.2348, 0.2555, 0.2038, 0.3656, 0.2245, 0.2495, 0.2063, 0.3762, 0.2209,\n",
       "        0.2316, 0.2121, 0.3784, 0.2306, 0.2525, 0.2185, 0.3690, 0.2284, 0.2465,\n",
       "        0.2150, 0.3637, 0.2380, 0.2555, 0.2141, 0.3535, 0.2328, 0.2764, 0.2240,\n",
       "        0.3484, 0.2300, 0.2525, 0.2192, 0.3381, 0.2285, 0.2704, 0.2090, 0.3339,\n",
       "        0.2255, 0.2794, 0.2095, 0.3287, 0.2355, 0.2555, 0.2089, 0.3391, 0.2406,\n",
       "        0.2316, 0.2002, 0.3425, 0.2339, 0.2764, 0.1941, 0.3330, 0.2359, 0.2525,\n",
       "        0.1957, 0.3351, 0.2471, 0.2256, 0.1895, 0.3448, 0.2458, 0.2316, 0.1815,\n",
       "        0.3391, 0.2397, 0.2495, 0.1809, 0.3313, 0.2481, 0.2316, 0.1797, 0.3403,\n",
       "        0.2552, 0.2525, 0.1708, 0.3446, 0.2491, 0.2495, 0.1659, 0.3343, 0.2496,\n",
       "        0.2346, 0.1683, 0.3322, 0.2607, 0.2674, 0.1647, 0.3427, 0.2639, 0.2286,\n",
       "        0.1549, 0.3411, 0.2580, 0.2226, 0.1533, 0.3308, 0.2629, 0.2525, 0.1560,\n",
       "        0.3348, 0.2733, 0.2376, 0.1494, 0.3443, 0.2726, 0.2764, 0.1405, 0.3389,\n",
       "        0.2677, 0.2286, 0.1399, 0.3286, 0.2728, 0.2644, 0.1283, 0.3280, 0.2743,\n",
       "        0.2316, 0.1213, 0.3204, 0.2694, 0.2256, 0.1148, 0.3286, 0.2648, 0.2316,\n",
       "        0.1149, 0.3298, 0.2533, 0.2644, 0.1200, 0.3402, 0.2539, 0.2435, 0.1292,\n",
       "        0.3359, 0.2591, 0.2316, 0.1289, 0.3259, 0.2533, 0.2256, 0.1291, 0.3315,\n",
       "        0.2432, 0.2525, 0.1382, 0.3377, 0.2465, 0.2495, 0.1435, 0.3283, 0.2502,\n",
       "        0.2256, 0.1412, 0.3228, 0.2405, 0.2465, 0.1450, 0.3318, 0.2345, 0.2256,\n",
       "        0.1543, 0.3328, 0.2410, 0.2226, 0.1568, 0.3216, 0.2396, 0.2346, 0.1549,\n",
       "        0.3232, 0.2282, 0.2226, 0.1622, 0.3322, 0.2277, 0.2525, 0.1701, 0.3259,\n",
       "        0.2332, 0.2256, 0.1683, 0.3166, 0.2267, 0.2316, 0.1684, 0.3229, 0.2170,\n",
       "        0.2704, 0.1782, 0.3280, 0.2197, 0.2226, 0.1833, 0.3180, 0.2220, 0.2764,\n",
       "        0.1789, 0.3135, 0.2123, 0.2226, 0.1827, 0.3223, 0.2057, 0.2495, 0.1930,\n",
       "        0.3214, 0.2105, 0.2495, 0.1931, 0.3100, 0.2096, 0.2555, 0.1910, 0.3108,\n",
       "        0.1982, 0.2376, 0.1970, 0.3203, 0.1955, 0.2376, 0.2059, 0.3216, 0.2026,\n",
       "        0.2525, 0.2155, 0.3160, 0.1996, 0.2316, 0.2198, 0.3109, 0.2091, 0.2376,\n",
       "        0.2303, 0.3137, 0.2053, 0.2316, 0.2271, 0.3247, 0.2052, 0.2614, 0.2231,\n",
       "        0.3239, 0.2160, 0.2376, 0.2330, 0.3186, 0.2192, 0.2405, 0.2394, 0.3268,\n",
       "        0.2143, 0.2525, 0.2332, 0.3346, 0.2201, 0.2346, 0.2350, 0.3289, 0.2299,\n",
       "        0.2376, 0.2462, 0.3278, 0.2281, 0.2376, 0.2474, 0.3388, 0.2256, 0.2495,\n",
       "        0.2410, 0.3414, 0.2349, 0.2405, 0.2474, 0.3343, 0.2415, 0.2376, 0.2568,\n",
       "        0.3398, 0.2374, 0.2674, 0.2527, 0.3495, 0.2421, 0.2256, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226,\n",
       "        0.2226, 0.2226, 0.2226, 0.2226, 0.2226, 0.2226])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reshape((371,4*150))\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudPointKernel(gpytorch.kernels.Kernel):\n",
    "    \"\"\"\n",
    "    Custom Kernel for 3D protein structures modeled as point clouds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(has_lengthscale=True, **kwargs)\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        # Compute pairwise squared Euclidean distance between point clouds\n",
    "        dist_sq = torch.cdist(x1, x2, p=2) ** 2\n",
    "\n",
    "        # Apply RBF-like kernel function\n",
    "        kernel_matrix = torch.exp(-0.5 * dist_sq / self.lengthscale**2)\n",
    "\n",
    "        return kernel_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProteinManifoldLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
