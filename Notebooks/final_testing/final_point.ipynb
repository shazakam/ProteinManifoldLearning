{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27faccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(\"../..\")  # Adjust if needed\n",
    "import pytorch_lightning as pl\n",
    "# Add the project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# from src.models.pointNetVae import PointNetVAE\n",
    "\n",
    "from src.models.PointNetVae_chamfer_split import PointNetVAE\n",
    "from src.utils.data_utils import *\n",
    "from src.dataset_classes.pointDataset import *\n",
    "from proteinshake.datasets import ProteinFamilyDataset\n",
    "from proteinshake.tasks import LigandAffinityTask\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3834f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27999/27999 [00:05<00:00, 5283.85it/s]\n",
      "100%|██████████| 31109/31109 [00:07<00:00, 4364.02it/s]\n",
      "100%|██████████| 25875/25875 [00:00<00:00, 45915.67it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = ProteinFamilyDataset(root='../../data').to_point().torch()\n",
    "idx_list = range(len(dataset))\n",
    "subset_size = int(len(dataset)//10)\n",
    "val_idx = random.sample(idx_list, subset_size)  # Get random subset\n",
    "train_idx = list(set(idx_list) - set(val_idx))\n",
    "\n",
    "test_subset =  PointDataset(Subset(dataset, train_idx), 500, return_proteins=True)\n",
    "filter_output = filter_by_max_length_and_pad(dataset,500, True)\n",
    "\n",
    "train_max = find_max_radius(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c028d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 24])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_enhanced_chamfer_distance(self, predicted_coords, true_coords, mask):\n",
    "    # Get L2 distances across points\n",
    "    AB_pwd = torch.cdist(predicted_coords, x2=true_coords, p=2)\n",
    "\n",
    "    # Create mask\n",
    "    mask = (mask.unsqueeze(-1).float() @ mask.unsqueeze(1).float()).int().bool()\n",
    "    masked_dist_matrix = torch.where(mask, AB_pwd, torch.tensor(float('inf'), device=mask.device)) \n",
    "\n",
    "    # Get min distance from A to B and B to A and sum\n",
    "    min_predicted_to_true, pred_to_true_min_idx = torch.min(masked_dist_matrix, dim = 1)\n",
    "    min_true_to_pred, min_true_to_pred_idx = torch.min(masked_dist_matrix, dim = -1)\n",
    "    \n",
    "    non_inf_sum = torch.sum(torch.where(torch.min(masked_dist_matrix, dim=-1)[0] != torch.inf, \n",
    "                                        torch.min(masked_dist_matrix, dim=-1)[0], \n",
    "                                        torch.tensor(0)), dim = -1)\n",
    "    \n",
    "\n",
    "    return 2*torch.mean(non_inf_sum)\n",
    "test_subset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_subset[0]\n",
    "x_true_indices = x[:,3:]\n",
    "x_true_indices = x_true_indices.argmax(dim=-1)\n",
    "x_true_indices[torch.where(torch.sum(x[:,3:], dim = -1) == 0)] = -1\n",
    "\n",
    "mask = (x_true_indices != -1)\n",
    "\n",
    "AB_pwd = torch.cdist(test_subset[1][:], x2=x, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aca88eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0694, -0.0862, -0.0261,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_subset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78a3dc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0859)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.sum((x[239] - test_subset[1][0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "288d3c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([239,  34,  32,  28, 247,  97, 213,  42,  57, 252,  59,  38,  55, 256,\n",
       "        209, 212, 212, 186, 216, 259, 177, 124, 151, 213, 213, 154, 213, 144,\n",
       "        144, 100, 192, 144, 166, 171,  83,  83, 118,  95, 204, 118, 205, 204,\n",
       "        203, 191, 189, 151, 194, 191, 222, 207,  87, 206, 197, 189, 191, 151,\n",
       "        190, 225, 178, 217, 217, 217, 219, 175, 209, 261, 215, 254,  83, 209,\n",
       "        254,  58,  83,  59,  83, 252, 254,  85, 249, 248,  62,  34, 238, 254,\n",
       "        242, 246, 247,  94, 246,  91,  88,  90, 118, 112, 112, 118, 118, 108,\n",
       "        112,  82,  67, 104, 104, 127, 127,  99,  97, 217, 213, 124, 186, 127,\n",
       "        169, 189, 217, 177, 190, 183, 150,  83, 274, 277, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278, 278,\n",
       "        278, 278, 278, 278, 278, 278, 278, 278, 278, 278])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(AB_pwd, dim = -1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749fac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 500])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB_pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProteinManifoldLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
